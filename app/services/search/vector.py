"""
Vector Search using PostgreSQL pgvector.

Provides semantic search over CV chunks using vector similarity.
The embeddings capture meaning, allowing searches like:
- "AI experience" to match "machine learning projects"
- "Team leadership" to match "managed a group of developers"

Uses pgvector's vector operators for efficient similarity search.
"""

import logging
from typing import List, Tuple, Optional, Dict, Any
from dataclasses import dataclass, field

from sqlalchemy import text
from sqlalchemy.orm import Session
from sqlalchemy.ext.asyncio import AsyncSession

from app.services.embedding.embedder import EmbeddingService, get_embedding_service
from app.config import get_settings

settings = get_settings()
logger = logging.getLogger(__name__)


@dataclass
class VectorSearchResult:
    """Result from vector search."""

    chunk_id: str
    candidate_id: str
    content: str
    enriched_content: Optional[str]
    similarity: float
    full_name: Optional[str] = None
    top_skills: List[str] = field(default_factory=list)
    section: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None


class VectorSearch:
    """
    Vector-based semantic search using pgvector.
    
    Uses cosine similarity for matching (via <=> operator in pgvector).
    
    Two types of search:
    1. Summary search: Search over candidate profile summaries
    2. Chunk search: Search over enriched CV chunks (granular)
    """

    def __init__(
        self,
        embedding_service: Optional[EmbeddingService] = None,
    ):
        """
        Initialize vector search.
        
        Args:
            embedding_service: Embedding service instance (defaults to singleton)
        """
        self.embedding_service = embedding_service or get_embedding_service()

    async def search_chunks(
        self,
        query: str,
        session: AsyncSession,
        top_k: int = 10,
        section_filter: Optional[str] = None,
        filters: Optional[Dict[str, Any]] = None,
    ) -> List[VectorSearchResult]:
        """
        Search CV chunks by semantic similarity with pre-filtering.
        
        Args:
            query: Search query text
            session: Database session
            top_k: Number of results to return
            section_filter: Optional section to filter (e.g., "experience")
            filters: Pre-filters applied BEFORE vector search:
                - location: Filter by candidate address
                - min_experience_years: Minimum years of experience
                - required_skills: Skills that must be present
            
        Returns:
            List of VectorSearchResult sorted by similarity
        """
        # Generate query embedding
        query_embedding = self.embedding_service.embed_query(query)

        # Format embedding as pgvector string: '[0.1, 0.2, ...]'
        # Embed directly in SQL since asyncpg has issues with ::vector cast syntax
        embedding_str = '[' + ','.join(str(x) for x in query_embedding) + ']'

        # Build SQL query with pre-filtering via JOIN to candidates table
        # Note: embedding_str is safe to embed directly as it's generated by our model, not user input
        sql = f"""
            SELECT 
                c.id as chunk_id,
                c.candidate_id,
                c.content,
                c.enriched_content,
                c.section,
                c.chunk_metadata as metadata,
                1 - (c.embedding <=> '{embedding_str}'::vector) as similarity,
                cand.full_name,
                cand.address,
                cand.total_experience_years,
                cand.top_skills
            FROM chunks c
            JOIN candidates cand ON c.candidate_id = cand.id
            WHERE c.embedding IS NOT NULL
        """

        params: Dict[str, Any] = {"limit": top_k}

        if section_filter:
            sql += " AND c.section = :section"
            params["section"] = section_filter

        # PRE-FILTERING: Apply hard filters BEFORE vector search
        if filters:
            # Location filter (case-insensitive partial match)
            if filters.get("location"):
                sql += " AND (cand.address ILIKE :location_pattern)"
                params["location_pattern"] = f"%{filters['location']}%"
            
            # Experience filter
            if filters.get("min_experience_years") is not None:
                sql += " AND cand.total_experience_years >= :min_exp"
                params["min_exp"] = filters["min_experience_years"]
            
            # Required skills filter (at least one skill matches)
            if filters.get("required_skills"):
                # Use JSON containment operator for skill matching
                skills = filters["required_skills"]
                skill_conditions = []
                for i, skill in enumerate(skills[:5]):  # Limit to 5 skills
                    param_name = f"skill_{i}"
                    skill_conditions.append(f"cand.top_skills::text ILIKE :{param_name}")
                    params[param_name] = f"%{skill}%"
                if skill_conditions:
                    sql += f" AND ({' OR '.join(skill_conditions)})"

        sql += f" ORDER BY c.embedding <=> '{embedding_str}'::vector LIMIT :limit"

        result = await session.execute(text(sql), params)
        rows = result.fetchall()

        logger.info(f"Vector search with filters returned {len(rows)} results")

        return [
            VectorSearchResult(
                chunk_id=row.chunk_id,
                candidate_id=row.candidate_id,
                content=row.content,
                enriched_content=row.enriched_content,
                similarity=row.similarity,
                full_name=row.full_name,
                top_skills=row.top_skills if hasattr(row, 'top_skills') and row.top_skills else [],
                section=row.section,
                metadata=row.metadata,
            )
            for row in rows
        ]


    async def search_candidates_by_summary(
        self,
        query: str,
        session: AsyncSession,
        top_k: int = 10,
    ) -> List[Tuple[str, str, float]]:
        """
        Search candidates by profile summary similarity.
        
        This is a high-level search for matching overall profiles.
        
        Args:
            query: Search query (e.g., job description)
            session: Database session
            top_k: Number of results
            
        Returns:
            List of (candidate_id, full_name, similarity) tuples
        """
        query_embedding = self.embedding_service.embed_query(query)

        # Format embedding as pgvector string - embed directly for asyncpg compatibility
        embedding_str = '[' + ','.join(str(x) for x in query_embedding) + ']'

        sql = f"""
            SELECT 
                c.id as candidate_id,
                c.full_name,
                1 - (c.summary_embedding <=> '{embedding_str}'::vector) as similarity
            FROM candidates c
            WHERE c.summary_embedding IS NOT NULL
            ORDER BY c.summary_embedding <=> '{embedding_str}'::vector
            LIMIT :limit
        """

        result = await session.execute(
            text(sql),
            {"limit": top_k},
        )

        return [
            (row.candidate_id, row.full_name, row.similarity)
            for row in result.fetchall()
        ]

    def search_chunks_sync(
        self,
        query: str,
        session: Session,
        top_k: int = 10,
        section_filter: Optional[str] = None,
    ) -> List[VectorSearchResult]:
        """
        Synchronous version of chunk search (for Celery workers).
        
        Args:
            query: Search query
            session: Sync database session
            top_k: Number of results
            section_filter: Optional section filter
            
        Returns:
            List of search results
        """
        query_embedding = self.embedding_service.embed_query(query)

        # Format embedding as pgvector string - embed directly for psycopg2 compatibility
        embedding_str = '[' + ','.join(str(x) for x in query_embedding) + ']'

        sql = f"""
            SELECT 
                c.id as chunk_id,
                c.candidate_id,
                c.content,
                c.enriched_content,
                c.section,
                c.metadata,
                1 - (c.embedding <=> '{embedding_str}'::vector) as similarity,
                cand.full_name,
                cand.top_skills
            FROM chunks c
            JOIN candidates cand ON c.candidate_id = cand.id
            WHERE c.embedding IS NOT NULL
        """

        params = {"limit": top_k}

        if section_filter:
            sql += " AND c.section = :section"
            params["section"] = section_filter

        sql += f" ORDER BY c.embedding <=> '{embedding_str}'::vector LIMIT :limit"

        result = session.execute(text(sql), params)

        return [
            VectorSearchResult(
                chunk_id=row.chunk_id,
                candidate_id=row.candidate_id,
                content=row.content,
                enriched_content=row.enriched_content,
                similarity=row.similarity,
                full_name=row.full_name,
                top_skills=row.top_skills if hasattr(row, 'top_skills') and row.top_skills else [], # Note: search_chunks_sync SQL needs to select full_name if not already doing so.
                                         # Checking previous SQL in search_chunks_sync...
                                         # The previous SQL for search_chunks_sync did NOT select full_name.
                                         # I need to update the SQL in search_chunks_sync as well in this same call or a separate one if I can't see it.
                                         # I can't confirm the SQL in search_chunks_sync selects full_name yet.
                                         # Wait, I see search_chunks_sync in previous turn (Step 264) did NOT select full_name?
                                         # Let's check Step 264 diff.
                                         # Step 264 updated search_chunks_sync SQL but DID NOT add JOIN candidates or select full_name.
                                         # I must update the SQL for search_chunks_sync as well.
                section=row.section,
                metadata=row.metadata,
            )
            for row in result.fetchall()
        ]

    async def search_with_expanded_queries(
        self,
        queries: List[str],
        session: AsyncSession,
        top_k: int = 10,
        filters: Optional[Dict[str, Any]] = None,
    ) -> List[VectorSearchResult]:
        """
        Search using multiple query variations (from query expansion).
        
        Combines results using max similarity for each chunk.
        
        Args:
            queries: List of query variations
            session: Database session
            top_k: Number of results
            filters: Pre-filters (location, experience, skills)
            
        Returns:
            Combined and deduplicated results
        """
        all_results: Dict[str, VectorSearchResult] = {}

        for query in queries:
            results = await self.search_chunks(query, session, top_k=top_k, filters=filters)

            for result in results:
                chunk_id = result.chunk_id
                if chunk_id not in all_results:
                    all_results[chunk_id] = result
                elif result.similarity > all_results[chunk_id].similarity:
                    all_results[chunk_id] = result

        # Sort by similarity and return top_k
        sorted_results = sorted(
            all_results.values(),
            key=lambda x: x.similarity,
            reverse=True,
        )

        return sorted_results[:top_k]


    async def find_similar_candidates(
        self,
        candidate_id: str,
        session: AsyncSession,
        top_k: int = 5,
    ) -> List[Tuple[str, str, float]]:
        """
        Find candidates similar to a given candidate.
        
        Useful for "candidates like this" recommendations.
        
        Args:
            candidate_id: ID of the reference candidate
            session: Database session
            top_k: Number of similar candidates to return
            
        Returns:
            List of (candidate_id, full_name, similarity) tuples
        """
        # Get the reference candidate's summary embedding
        sql = """
            SELECT summary_embedding
            FROM candidates
            WHERE id = :candidate_id AND summary_embedding IS NOT NULL
        """

        result = await session.execute(
            text(sql), {"candidate_id": candidate_id}
        )
        row = result.fetchone()

        if not row or not row.summary_embedding:
            return []

        ref_embedding = row.summary_embedding

        # Format embedding as pgvector string
        # Handle case where ref_embedding might be a string or list
        if isinstance(ref_embedding, str):
            embedding_str = ref_embedding
            if not embedding_str.startswith('['):
                # Should be list
                pass 
        else:
            embedding_str = '[' + ','.join(str(float(x)) for x in ref_embedding) + ']'

        # Find similar candidates
        sql = f"""
            SELECT 
                c.id as candidate_id,
                c.full_name,
                1 - (c.summary_embedding <=> '{embedding_str}'::vector) as similarity
            FROM candidates c
            WHERE c.id != :candidate_id 
              AND c.summary_embedding IS NOT NULL
            ORDER BY c.summary_embedding <=> '{embedding_str}'::vector
            LIMIT :limit
        """

        result = await session.execute(
            text(sql),
            {
                "candidate_id": candidate_id,
                "limit": top_k,
            },
        )

        return [
            (row.candidate_id, row.full_name, row.similarity)
            for row in result.fetchall()
        ]
